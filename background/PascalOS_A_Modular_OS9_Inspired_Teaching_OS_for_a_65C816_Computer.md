# PascalOS: A Modular OS-9-Inspired Teaching OS for a 65C816 Computer

# 1. Boot Sequence & Early Bring-Up

ROM Layout & Reset: On power-up, the 65C816 CPU fetches its reset vector from a fixed ROM address ($FFFFC/$FFFFD$) 1 , starting in emulation mode (6502-compatible) 2 . This means the processor initially behaves like an 8-bit 6502, limiting access to the lowest 64KB and forcing the boot code (and stack) to reside in bank $00$ 3 . The system's ROM is divided into two parts: a minimal monitor/boot ROM at the top of memory (e.g. the highest 32-64KB), and possibly a small bootloader stub at the reset vector location if separate. The ROM's responsibilities include low-level hardware init and loading the kernel.

Reset-to-Monitor Flow: Upon reset, execution begins at the ROM's start-up routine in assembly. Step 1: The ROM code performs basic CPU init – it sets the program bank to $00$, the data bank to $00$, the direct page to $00$, and initializes an initial stack pointer in page $01$ (as required in emulation mode). Step 2: It then executes the special sequence to switch the CPU into native 16-bit mode (via the XCE instruction to clear the emulation flag) 4 . In native mode, the 65C816 can use the full 24-bit addresses (16MB space) and 16-bit registers. The ROM now relocates the stack pointer to a safe area (still within the identity-mapped low memory for now).

Minimal Monitor: After basic CPU setup, the ROM runs a minimal monitor program. This monitor is a simple firmware interface that can perform low-level I/O (e.g. serial console output, simple command parsing) and is mainly present for educational value and debugging. It may display a prompt or at least provide a way to examine memory/registers if needed. Its primary job, however, is to locate and load the PascalOS kernel. For example, the monitor might read a disk sector or flash memory region that contains the OS kernel image. This stage is kept minimal (perhaps just a few KB of assembly) to avoid complexity in ROM.

Kernel Loader: The monitor's loader routine copies the PascalOS kernel image from persistent storage (an SD card or flash) into RAM (presumably starting at a known physical address). Once loaded, the ROM must transfer control to the kernel's start in a clean way. Step 3: The ROM sets up the CPU state for the kernel entry - e.g. sets the program bank to match where the kernel is loaded, adjusts the stack if needed, and ensures interrupts (including the MMU fault NMI/Abort) are properly vectored. Certain early boot steps require assembly, such as toggling CPU mode, setting up hardware registers (like the CPLD MMU registers), and handling the 24-bit addressing intricacies - these cannot be done in high-level Pascal.

Enabling the MMU: Initially, the MMU (memory management unit) is kept disabled or in identity-map mode during the loading process, so that the kernel can be loaded into a known physical address without translation issues. After the kernel's code and static data are in RAM and the CPU is in native mode, the bootstrap code enables the DAT MMU. This involves configuring the MMU's page table in SRAM for the kernel's address space. The kernel might reserve a specific ASD (address space ID) or context number for itself (for example, ASD 0 for kernel). The ROM (or kernel's start code) fills the MMU's table entries so that

the kernel's logical 64KB (especially the top portion for kernel, see below) maps to the correct physical frames where the kernel resides. Once the MMU is turned on (by setting a control register in the CPLD), any memory access is translated through the page table.

Hand-off to SuperPascal Kernel: Step 4: The final ROM action is to jump to the kernel's entry point, now running under the MMU. At this point, control transfers from assembly to the high-level SuperPascal code of the kernel. The transition is done carefully: registers are loaded with any required startup parameters or a clean state. For instance, the ROM might pass a pointer (in a CPU register) to a boot info structure or simply start the kernel at a known label with no arguments, but with all hardware (timers, devices) at default state.

First Kernel Task: The kernel entry (now in SuperPascal) performs early initialization: it sets up internal structures (like free memory lists, the module directory, device tables) and then creates the first process – often called the "init" process. This first process could be a simple shell or an initial program that the OS runs (similar to how OS-9's Init module spawns the user shell). Creating the first task involves allocating a process descriptor, assigning it a free ASD and memory pages, loading a program module (e.g. a simple command-line shell or demo program), and placing it in the ready list. Finally, the kernel calls the scheduler or performs a context switch to start executing the first user-level task.

Why Assembly in Boot: Many of the above steps (reset vector handling, switching modes, enabling the MMU, low-level device init) must be in assembly because they require direct hardware manipulation and occur before any high-level runtime exists. For example, setting up the stack pointer and CPU flags has to happen before Pascal code can run. The assembly stub ensures the environment is ready for Pascal - after which the goal is to remain in Pascal for most of the OS logic. The hand-off is done by making the assembly stub simply call or jump into a Pascal procedure (e.g. KernelStart) so that from that point on, PascalOS runs in a high-level language, improving clarity and safety.

# 2. Kernel Architecture (SuperPascal-First)

SuperPascal-Centric Kernel: The kernel of PascalOS is intentionally kept small, modular, and written predominantly in SuperPascal. By implementing the core OS in a high-level language, we ensure the code is readable and verifiable by students. The kernel follows a microkernel-like structure inspired by OS-9's modular design - most services (file system, drivers, etc.) are not baked into a monolithic kernel binary but are separate loadable modules (see Section 5). The kernel's job is primarily to manage processes, memory mapping, and basic IPC, and to provide fundamental system call handlers. Writing these in SuperPascal leverages the language's safety features (no arbitrary pointers, strong typing) to avoid common bugs.

Kernel Memory Layout: We divide the 65C816's 64KB logical address space into a user region and a kernel region. The top 8KB page (addresses $E000$-$FFFF$ in each logical map) is reserved as the kernel window, while the lower 56KB ($0000$-$DFFF$) is for user-space. This is analogous to OS-9's approach of mapping part of each process space to the OS 5 6. The kernel's code and data reside in physical memory (e.g. high RAM), and the MMU maps that physical region into every process's top page. In effect, the kernel is always present at the same logical addresses in every context (though possibly marked read-only for user mode). This simplifies system calls: user programs can trap or jump to fixed addresses in this high memory region to request services. The kernel window mapping means the OS code doesn't need to

be duplicated per process and allows easy sharing of data between user and kernel (e.g. for copying buffers during I/O).

Kernel vs User Mode: Although the 65C816 CPU has no separate privileged mode, we enforce a logical separation. User code is meant to run only in the lower 56KB region, and the top 8KB is reserved for kernel routines and data structures. The MMU's per-page protection bits help enforce this: we mark the kernel's page as not writable (and even not executable for user) so that if user code erroneously jumps or writes into $E000-$FFFF$, the MMU will trigger a fault (via the Abort/NMI line). Thus, while hardware doesn't have a ring level, the combination of MMU and language safety simulates a user/system boundary. All kernel-entry points (system calls) are carefully defined at known addresses or via a software interrupt mechanism (e.g. a trap instruction or a jump table in the kernel page).

Cooperative Scheduling Simplifies Concurrence: PascalOS uses cooperative multitasking (see Section 6), meaning the kernel never preempts a running task arbitrarily  $^{10}$ . This greatly simplifies kernel design: the kernel code is never concurrently entered by multiple processes. Only one process runs at a time until it yields control. Therefore, the kernel can be non-reentrant and mostly free of complex locking. As long as a process is executing in kernel mode (handling a system call), it will not be interrupted by another task. This eliminates many race conditions and means critical kernel data structures can be updated with minimal synchronization. In an educational context, this is crucial - it allows students to reason about kernel behavior sequentially, rather than juggling interrupts or preemptive context switches.

Avoiding Reentrancy Hazards: Because of cooperative scheduling, kernel routines don't need to be reentrant - an important invariant that avoids tricky bugs. For example, memory allocators or device drivers in the kernel can assume they won't be re-entered by a second process halfway through. This is in stark contrast to preemptive kernels where any piece of code might be interrupted. As a result, functions don't have to be reentrant, and data structures don't need elaborate locks 11 . We do, however, disable external interrupts (like hardware IRQs) when necessary if they could interfere with sensitive sections (e.g. during MMU update or context switch), though many devices can be polled cooperatively as well.

Assembly vs SuperPascal - Division of Labor: Only a few low-level parts of the kernel are in assembly: - The interrupt and trap handlers stubs (e.g. NMI/Abort handler that catches MMU faults, IRQ handler for timer or devices) are written in assembly to properly save registers and switch to the kernel context. - The context switch routine (saving CPU state, changing stack pointer, loading new MMU context, etc.) is in assembly, as this requires direct register manipulation and no high-level overhead. As an example, the context switch will save all 65C816 registers (A, X, Y, D, DB, PB, etc.), then load the new process's registers and perform an RTI or jump - this kind of precise control is easier in assembly  $^{12}$ . - The bootstrapping code (as described in Section 1) remains in assembly until it calls into the Pascal kernel.

Everything else – scheduling logic, memory management algorithms, file system, device driver framework, etc. – is implemented in SuperPascal. This includes the scheduler policy, process table management, module loader, and so on. Writing these in Pascal ensures that the kernel is expressed in a high-level, structured manner, with strong type checking and memory safety. For example, the kernel will use Pascal records to represent process descriptors (instead of raw struct accessed via pointers in C). Many typical sources of errors (buffer overflows, wild pointers) are prevented by the language. The assembly routines are kept as simple as possible and call into Pascal code as quickly as they can. This clear separation (assembly only for what absolutely cannot be done in Pascal) maximizes the inspectability of the OS code – students

can read and understand the bulk of the OS in a high-level language, demystifying the operating system's inner workings.

# 3. Process Model (OS-9 Inspired, Not Unix)

OS-9 Style Processes: PascalOS adopts a process model heavily inspired by Microware OS-9, with lightweight, modular processes rather than heavy Unix-style processes. Each process has a dedicated 64KB logical address space (the maximum addressable by the 65C816's 16-bit registers in one context). Within that 64KB, a process has its own code, data, heap, and stack segments. A process descriptor (a Pascal record in the kernel) holds the metadata: - Register save area (for A, X, Y, etc., when the process is not running), - The process's MMU page mappings (or an index/ASID referencing its entries in the global page table), - Pointers or offsets to the process's code, static data, heap, and stack areas, - Scheduling state (ready, waiting, etc.), - Possibly a parent or creator ID if we track parental relationships.

The process descriptor is akin to OS-9's process table entries, containing information needed to manage and restore the process  $^{13}$ $^{9}$ . We ensure the structure is kept minimal for simplicity.

Memory Layout per Process: In each process's 64KB logical space, we organize memory in a simple way. Typically: - The code (text) and constant data of the program's module are loaded starting at the bottom (logical address 0x0000 by convention). Because modules are position-independent and relocatable, they can be loaded at any logical address; we choose low memory for simplicity. - The heap (dynamic memory) grows upward from the end of the program's static data area. - The stack is allocated at the top of the user region and grows downward. For example, if the top 8KB is reserved for kernel, the stack might start just below 0xE000 and grow downwards. - Any OS-9 style data modules (shared memory segments) or additional code modules mapped into the process can occupy other 8KB pages within the 64KB space, if needed. By default, a new process might use pages 0-6 for its program (code+data+heap) and page 7 as the kernel window.

Each process effectively has its own "logical 0-0xFFFF" view. The actual physical memory backing those addresses is set up via the MMU when the process is created (see Section 4). Fragmentation is avoided by using page allocation; the process's memory needs (code size, data size, stack size) are rounded to 8KB pages.

Process Creation (Spawn vs Fork): Unlike Unix, PascalOS does not implement fork() (which duplicates an entire process). Instead, it follows the OS-9 approach of starting new processes from scratch via a spawn (often called Fork in OS-9 terms, but it actually loads a new program). To create a process, a program module must be loaded - either already in memory as a module or fetched from disk. The kernel provides a call (e.g. ProcessCreate(name, params)) that: 1. Finds or loads the module (executable code) by name. 2. Allocates a new process descriptor and a set of free physical pages for the process's memory. 3. Copies the module's code into the new pages (if not already resident as a shared module). 4. Sets up the initial stack frame for the process, including argument passing or initial register values. 5. Inserts the process into the scheduler's ready list.

This is analogous to OS-9's system call F\$Fork which executes a module as a new process, or F\$Chain which replaces the current process image 14 . We prefer spawn-new semantics for pedagogical clarity - each process begins life running a specified program module, rather than being a clone of an existing one.

Parent/child relationships are minimal: the creating process may get back a process ID and possibly wait for the child's termination, but we don't enforce a strict parent-child dependency beyond that (processes do not automatically inherit resources or communicate implicitly as in Unix fork).

If a parent wishes to be notified of child termination, we provide a simple mechanism (e.g. the parent can call WaitPID or receive a signal message). However, the model is flexible: in an educational setting, we might omit parent-child hierarchies entirely and allow any process to join another if needed, or simply leave cleanup to the kernel.

Process Termination: When a process calls an exit system call or falls off the end of its program, the kernel performs cleanup: - All memory pages owned by the process are freed (except any shared module pages with other users, which are handled via reference counts). - The process descriptor is removed from the table and recycled. - Any references to the process (in IPC objects, etc.) are cleaned up or signaled. - If a parent waiting, it's notified (e.g. via a return code or setting a flag). If not, the resources are just reclaimed.

If a process crashes (e.g. illegal memory access triggers an MMU fault), the fault handler in the kernel will terminate the process (see Fault Handling, Section 10) similarly, ensuring it cannot corrupt others.

MMU ASIDs and Page Tables: The external MMU (in CPLD) maintains a global page table in SRAM, which can hold mappings for multiple processes. We designate an ASID (address space identifier) for each active process. For example, if the MMU supports 256 contexts, the OS might use an 8-bit ASID. Creating a process involves allocating an unused ASID (recycling an old one if available). The kernel then populates the 8 entries (for  $8 \times 8\mathrm{KB}$  pages) in that process's slot in the MMU's table. This could mean writing into the SRAM at an index derived from the ASID. When a context switch occurs, the kernel simply tells the MMU to use the new ASID (e.g. writes the ASID to an MMU register), and from then on the hardware translates addresses according to that process's mapping. If the MMU does not directly support ASID registers, the kernel will load each of the 8 page registers on each switch (still, the data is taken from the stored page table structure).

When a process terminates, its ASID becomes free. The kernel can then re-use that ASID for new processes. However, before reuse, it invalidates or clears the old mappings in the table to avoid stray translations (for security, one process shouldn't accidentally see another's memory if an ASID is reused). The MMU may have a global valid bit per entry  $9$ , which the kernel will clear for all pages of the dying process (or simply overwrite them with a safe mapping).

Containment of Crashes: Thanks to the separate address spaces, a bug or crash in one process should not affect others or the kernel. If a process tries to access an address in a page that is not mapped or violates permissions (e.g. writing to a read-only page), the MMU will raise an Abort exception (wired to the 65C816's ABORT or NMI line)  $7$ . The kernel's abort handler will catch this and determine which process caused it. It can then print an error (for example: "Process X caused memory violation at address Y") and gracefully terminate the offending process. The rest of the system continues running. This behavior is analogous to OS-9's error handling where a process abort could be caught and reported without bringing down the whole OS  $9$ . By making faults non-fatal to the OS, students can experiment with processes that may crash without needing a full system reboot – a valuable feature for learning and debugging.

# 4. Memory Management Model

Philosophy - Clarity Over Complexity: PascalOS's memory management is deliberately kept simple and deterministic, favoring educational clarity over advanced features. We use flat memory with fixed-size pages and no demand paging or swapping. Every decision here is justified by making the system easier to understand for students building their own hardware.

Logical vs Physical Memory: Each process deals with logical addresses (0-64KB) which the MMU translates to physical addresses (0-16MB). This is classic virtual memory, but without the complexities of paging to disk - all translations are backed by real RAM. The 16MB physical RAM is the true memory of the machine, shared by all processes but partitioned by the OS. Because of the 8KB page size, physical memory is conceptually divided into 2048 frames of 8KB each. We maintain a simple free frame list or bitmap to track which frames are free. When a new page is needed (for a new process's stack, heap growth, or module loading), the kernel allocates from this list.

Page Allocation & Fragmentation: Allocation is done in whole 8KB chunks. This coarse granularity is chosen for hardware simplicity (mirroring the 8KB MMU blocks of the CoCo3's DAT). Internal fragmentation (wasted space within a page) is a known trade-off - e.g. if a process only needs 1KB for code, it still occupies an 8KB frame - but in an educational context this is acceptable. It simplifies the MMU and memory bookkeeping dramatically. External fragmentation (scattered free blocks) is minimized by the fact that all allocations are same-size frames; the free list can be a bitmap where each bit represents a frame  $^{15}$ . Allocating is a matter of finding the next free bit, and freeing is clearing that bit - a concept students can easily grasp.

No Overcommit, No Swap: PascalOS does not implement swapping or virtual memory beyond physical RAM. If memory is full (no free 8KB frames), the OS will simply not allow new processes or allocations until memory is freed (it can report an "out of memory" error). This is by design: adding paging to disk or swapping would complicate the system and make it non-deterministic in timing. We want all memory accesses to be fast and predictable (important since the hardware is deterministic and for real-time behavior in experiments). Moreover, keeping everything in RAM allows the memory management to be explained with simple diagrams and without involving disk I/O in the memory subsystem.

Shared Pages for Efficiency: The OS-9 heritage encourages shared code and data when possible. If two processes execute the same program or library module, PascalOS will load that module's code only once in physical memory, and then map that same frame into both processes' logical spaces (marked read-only if appropriate). For example, if "Editor.bin" is a module of 12KB code, the OS might allocate two 8KB frames to load it. Any process that runs the editor will have those two frames mapped into its address space for the code segment, rather than creating separate copies. This not only saves memory but also reflects the educational goal of demonstrating dynamic linking: students can see that one physical memory block can be present in multiple address spaces 16 6 . We also allow the concept of shared data modules (as OS-9 did) – a process can create a named data module which is essentially a block of memory that another process can map into its space for shared memory IPC (see Section 7). These data modules are tracked in the module directory and have reference counts.

Memory Protection Rules: Every allocated page is assigned a set of permissions: Valid, Read/Write (or read-only). Execution permission is not hardware-enforced by the 65C816's MMU (it doesn't have an execute bit), but the OS can enforce it in software by not mapping user pages that contain OS code as executable,

etc. In practice, code pages are marked read-only, data pages read-write, and the kernel's page is marked system-only. If a write is attempted to a read-only page, or an access to an unmapped page, the hardware triggers an abort which the OS handles. This ensures memory safety across processes - one process cannot write to another's memory, and cannot even see it since no mapping exists outside its 64KB space

Coarse 8KB Paging – Why Acceptable: An 8KB page size may seem large on a 64KB address space (only 8 pages per process), but it matches the design of historical systems (OS-9 Level 2 on 6809 also used 8KB blocks). Educational justification: using 8KB pages means each process has at most 8 pieces of memory to worry about, making it feasible to draw the entire memory map of a process on a whiteboard. Students can manually compute logical-to-physical translations for any address by splitting the address into a page number (3 high-order bits) and offset (13 low-order bits) given the page table. The coarse granularity also aligns with typical module and code sizes, meaning most programs will just occupy a few 8KB pages. Since this OS doesn't aim to run huge programs, the fragmentation cost is negligible in practice. Simpler MMU hardware (the CPLD) is another reason – addressing 8KB boundaries reduces the size of the mapping SRAM and logic needed.

No Virtual Memory = Deterministic Performance: Because we have no paging to disk, any memory access either hits in RAM or triggers an abort (if invalid) – no unexpected slow page faults that load data from disk. This makes the system's timing much more predictable. In a classroom setting, this determinism allows consistent behavior run-to-run and makes performance analysis easier (no worrying about page-in times). It also mirrors early microcomputer OSes which didn't have complex VM. We can tell students: "If your program fits in RAM, it runs; if not, you get an out-of-memory error – nothing magically slows down or shifts in the background." That transparency is pedagogically beneficial.

In summary, the memory model is intentionally simple yet illustrative: it demonstrates fundamental concepts of virtual vs physical addressing, paging, and protection, but steers clear of advanced features that would obscure the clarity (like multi-level page tables, TLBs, page replacement algorithms, etc.). The emphasis is on students being able to understand and even modify the memory management with confidence. All of the policy and management (free lists, mapping, etc.) is written in high-level SuperPascal code, making it accessible to modify and experiment with.

# 5. Module System (Core OS-9 Concept)

Modular OS Design: One of the crown jewels of OS-9 was its memory module system, and PascalOS embraces this concept at its core 18 19 . Rather than large monolithic executables, all code (including the kernel, drivers, applications) is packaged as relocatable modules. A module is a self-contained binary containing a header, the code/data body, and a checksum. The module system provides dynamic linking and sharing in a way that's far simpler than, say, ELF binaries on Unix.

Module Format: Every module begins with a module header containing metadata: a unique name, a type (e.g. program, driver, file manager, data), a size, an edition/version number, and flags for attributes like reentrancy or whether it's system (privileged) code 20 21 . There is a special sync pattern (in OS-9 it was 0x4AFC) and a CRC at the end for integrity 22 . After the header, the module body contains the actual code (typically position-independent) and any static data or relocation info. For a program module, the header also includes fields like the offset to the execution start, the needed static data size, and stack size 23 24 . This means the module itself tells the OS how much memory to allocate for its data and stack when

launching it - a very educational design, as students can see these requirements clearly in the module definition.

Relocation & Linkage: Modules are stored in a position-independent form with relocation records (if needed) or simply using PC-relative code. When the OS loads a module into memory, it may need to fix up addresses. In OS-9/6809, the code was compiled to be position-independent (no absolute addresses), and any external references were resolved through an export/import table if linking modules together. In PascalOS, we simplify by initially focusing on modules that are self-contained (no unresolved external references except OS calls). If there are dynamic links between modules, we implement a simple export table: a module can declare some global symbols as exported, and other modules can import them by name. The OS loader will then fix up those references at load time by looking up the addresses of the exports in already-loaded modules (similar to how OS-9 supports dynamic linkage between modules) 25 16 . All of this is done in a straightforward way in Pascal code (or via a small relocation routine).

Loading Modules: Modules can reside on disk (or ROM) as files. The OS maintains a Module Directory, which is a list of all modules currently loaded in memory 25 . At boot, the kernel's own core and essential drivers are already present (some may be in ROM, others loaded from disk into memory and entered in the directory). When a request is made to execute a program by name, the OS first checks the module directory: if the module is already in memory, it increments its link count and uses it 16 ; if not, the OS finds the module file on disk, loads it into a free memory area, verifies the CRC, installs it into the module directory, and then uses it. This means subsequent executions of the same program don't re-load code from disk - they reuse the in-memory copy, which is great for limited memory and an important concept for students (it's like an in-RAM cache of executables).

Sharing & Reentrancy: By default, program modules in OS-9 are reentrant, meaning multiple processes can use the same code simultaneously without conflict 18. They achieve this by not storing global state in the code area; instead, each process gets its own data area (the kernel allocates the "Memory size" and "Stack size" specified in the module header for each new instance 24 26). PascalOS adopts the same idea. For example, if two users run the text editor module, there will be one copy of the editor's code in RAM, but each process will have its own data section and stack allocated (as per the module header requirements). The code will reference data via an indirection (like an offset from a base register pointing to that process's data area), which the OS will set up before giving control to the process. This way, the code can be pure (shared) while data is per-process - a key concept in reentrant code.

Module Types - OS Components: We also use modules for OS components: - The kernel itself can be thought of as a set of core modules (though linked together at compile-time for bootstrap). - Device drivers are modules of type "Driver" and have standardized entry points (like init, read, write routines). They are loaded into memory and the kernel knows how to call into their entry table 27 28 . - File managers (for filesystem handling) are modules. - Even the initialization module (often called "Init" in OS-9) that spawns the shell is a module loaded at boot 29 . - Data modules can be created as chunks of memory that processes can share or use for communication 30 .

All these reside in the same uniform module directory. This uniformity is extremely useful educationally: whether it's an application or a driver, it's managed the same way by the OS (loaded, identified by name, relocated, tracked by link count).

Naming and Versioning: Modules have names (up to a certain number of characters, e.g. 32). The OS-9 module directory was flat (all names global)  $^{31}$ , whereas OS-9000 introduced a hierarchical namespace. We will keep it simple and use a flat namespace or a simple prefix scheme if needed (e.g. drivers might have names like "SCF.Serial" etc.). Each module also has an edition (version number) and possibly a checksum. If a new version of a module is loaded, it can replace the old one, or multiple versions could coexist if we allow (but likely not needed here). For teaching, the version field can be used to illustrate the concept of version control in deployed systems (e.g., "Module X v1.2").

Educational Advantages Over Monolithic Binaries: Using a module system instead of monolithic executables (as in Unix) has several benefits: - Transparency: Students can inspect a module's header to see exactly its requirements (size, entry points). This demystifies how programs are represented in memory. - Simpler Linking Model: No complex linker scripts or relocation records for an entire OS image; instead, each module is like a building block with a well-defined interface. - Dynamic Loading: They can see how an OS loads code on the fly. For instance, a new device driver can be loaded at runtime by just telling the OS to load that module file - no need to rebuild the kernel. This is far more approachable than, say, loadable kernel modules in Linux which require careful kernel build or inmod tooling. - Memory Efficiency: Shared modules mean we don't waste memory on duplicate code. In a constrained environment (16MB RAM for everything), this is important and also teaches the value of sharing and reentrancy. - Analogy to Modern Systems: We can relate modules to shared libraries or DLLs in modern OSes, but here everything is explicit and under the student's control (no runtime loader hidden behind the scenes - our loader is part of the OS they can read).

In comparison to Unix executables (ELF, etc.), our module format is simpler and self-descriptive. Unix binaries typically rely on an external loader and lots of system support to run; our modules carry their own metadata which the OS can directly use. OS-9's designers intended the system to be modular for flexibility in embedded systems 32, but it turns out to be a fantastic approach for teaching because you can replace pieces easily and see how they fit together.

We also encourage students to write their own modules in SuperPascal. The SuperPascal compiler can target our module format (either directly, or via an assembler that wraps the output in a module header and CRC). This means a student could write a new application in SuperPascal, compile it to a module, load it into the OS, and run it – all while being able to examine the module's structure and the OS's management of it. This end-to-end visibility is exactly what "understood end-to-end" is about.

# 6. Scheduler & Cooperative Multitasking

Cooperative Multitasking: PascalOS employs a cooperative scheduler, meaning that tasks voluntarily yield control rather than being preempted by the OS on a timer tick 10. In this system, the scheduler is simple: it's essentially an idle loop that picks the next ready task once the current task gives up the CPU. Each process runs to completion of its timeslice (or until it waits for I/O or explicitly calls Yield) before another runs. All tasks must cooperate by yielding periodically or when idle, hence the name. This design is true to classic OS-9 (which on 6809 was effectively cooperative) and is ideal for teaching because the execution is easier to follow.

Task States: We define a few fundamental states for a task: - Running: exactly one task is running (until it yields). - Ready: tasks that are ready to run (not waiting on anything) are in a round-robin queue. - Waiting/

Blocked: tasks waiting for an event or I/O (not eligible to run). - Terminated: finished tasks awaiting cleanup.

Because there's no preemption, there's actually no need for a "blocked" task to be preempted mid-computation - a task only moves to waiting when it voluntarily performs a blocking operation (like waiting on a message or I/O). Thus, state transitions happen at well-defined points in the code (no surprise context switches).

Yield Protocol: A key system call provided by the kernel is Yield (or it could be implicit in certain calls like reading from a device that has no data). When a task calls Yield, the kernel's scheduler is invoked to perform a context switch. The steps: 1. Save the CPU context of the current task (all registers, program counter, etc.) into its process descriptor. 2. Move the current task's descriptor to the ready queue tail (or to waiting list if it yielded with a specific wait condition). 3. Select the next task from the head of the ready queue. 4. Load that task's saved context (restoring registers, etc.) and switch the MMU to that task's ASD. 5. Resume execution of the new task.

This context switch is performed by a small assembly routine for efficiency, as described in Section 2. The mechanism is straightforward since we are single-core and cooperative: the currently running task is fully in control of when this happens.

Avoiding Starvation: One might worry that a greedy task could hog the CPU. In cooperative systems, it is indeed possible for a badly behaved task to starve others by never yielding  $^{33}$ . Our strategy to avoid this is two-fold: - Design and Education: We instill in developers (the students themselves) the need to place Yield calls in long-running loops or computations. This is part of cooperative multitasking discipline. -

Yield on I/O: The OS will automatically yield in certain scenarios. For example, if a task performs an I/O operation that cannot complete immediately (like reading from an empty pipe or waiting for a timer), the OS will block that task and switch to another. This ensures that tasks waiting on events don't spin forever and starve others. - We might also introduce a simple watchdog or tick that checks if the system is alive - e.g. a hardware timer NMI that doesn't preempt tasks but could detect if the system is completely hung and reset or warn. However, the primary approach is cooperative discipline rather than enforced preemption.

Because the user programs are likely written by the students themselves (or provided in examples), we can assume they will follow the cooperation contract. This is a reasonable assumption in a controlled educational setting (unlike a general-purpose OS with arbitrary third-party programs).

No Preemption – Simplified Correctness: By deliberately excluding preemptive scheduling, we eliminate a huge class of complexity. There is no need for complex locking mechanisms or interrupt-driven race conditions in most of the OS. Debugging is far easier: a bug is reproducible simply by following the deterministic sequence of yields, rather than having to worry about timing-dependent issues. As a concrete example, if two tasks and the kernel are printing to the console, in a cooperative system their outputs won't intermix unpredictably at the character level – each print happens wholly during that task's timeslice (unless it explicitly yields mid-print). This predictability is golden for teaching; it means when something goes wrong, students can trace it logically rather than suspecting a context switch at a bad moment. Cooperative multitasking “allows much simpler implementation of applications because their execution is never unexpectedly interrupted by the process scheduler” 11. This includes the kernel itself: we don’t have to make every kernel routine reentrant or guard every shared structure with a mutex, as discussed.

Scheduler Implementation: The scheduler is essentially an infinite loop (in the idle task) or a procedure that gets called whenever the current task can't continue. For fairness, we implement it as a round-robin: whenever a task yields, it goes to the back of the ready queue and we run the next one at the front. If tasks voluntarily yield often, all tasks get a chance to run in a cyclic order, achieving a crude fairness. Since there are no priorities (initially) in our design, starvation is only possible if someone never yields. We may add a debug check: if an interrupt (like a millisecond timer) is enabled, it could increment a counter and if it finds the same task running for a very long time without yielding, it could log a warning – but it still won't force preemption. This is just to catch mistakes in student code (like forgetting a yield in a long loop).

Context Switch Mechanics: When a context switch occurs (on yield or block), what exactly is saved/restored? For the 65C816, we save: - The program counter (which includes the 16-bit address and the current program bank register PB for the 24-bit PC). - The data bank register (DB) because different tasks might use different DB for addressing data. - The direct page register (D) if tasks utilize different zero-page setups. - The processor status (P) which includes flags and the important Memory/Index register size flags (M and X) and the interrupt disable status. We'll standardize that tasks always run with a known state for these flags (e.g. 16-bit mode for A and X), so context switch will preserve whatever the current values are. - The accumulator A and index registers X, Y. - Stack pointer (S) - each process has its own stack, so we must switch to the new process's stack pointer. This is a crucial part of the context. - Additionally, we must handle the MMU: either load the new task's page registers or set the MMU's context register to the new ASID.

All these together constitute the CPU context. We can save them in the process's descriptor in memory. The assembly Yield routine does this efficiently, often by pushing registers onto the stack or into a known memory area. Then it picks the next task and reverses the process (pop registers, etc.). The key point is that when it jumps back to user code, "it leaves no traces on the stack or in registers so when code resumes execution it has no idea anything happened" 12 - the task continues seamlessly from where it left off.

Stack Management: Each process's stack is in its own memory space, so one task's deep recursion can't crash another. The context switch ensures the CPU's SP register is changed to the new task's stack base. We guard against stack overflow by allocating sufficient stack (the module header's M$Stack field suggests a minimum 26 , and the OS might fill some guard pattern beyond to catch overflow in debugging).

Interrupts and Scheduling: We do have hardware interrupts (like maybe a timer tick or serial input) which are asynchronous. How do these interact with our cooperative scheduler? Typically, if a hardware interrupt occurs, an assembly stub will quickly service it or mark something (like incoming data available) and then return. We do not do a full context switch on timer interrupts as a preemptive OS would. Instead, after returning from the interrupt, the same task continues. If that interrupt signaled a condition that a higher-level task was waiting for (like a device input), the OS will mark that waiting task as ready but not switch to it immediately. The currently running task still needs to cooperatively yield or finish. This approach keeps interrupts simple: they never perform a task switch directly, they just set flags that the main scheduler loop will notice. The rule is that task switches only happen at well-defined yield/block points, never truly in the middle of a thread of execution unexpectedly.

By simplifying multitasking to this cooperative scheme, we trade off some robustness (one malicious loop can hang the system) for maximum simplicity. This is acceptable for our educational goals - it reflects the style of early single-user OSes and embedded systems, where well-behaved programs yielded to one another.

We also can implement optional features to enrich understanding: - For example, we could implement a time-slicing mechanism where if a task runs for too long (based on a timer), the OS sets a flag and when (and only when) the task next calls a system service, the OS notices and yields to another task (this is a form of cooperative-multitasking with periodic checks). But initially, we keep it pure cooperative.

The end result: the scheduler can be explained in 20 lines of pseudo-code, the context switch perhaps 30 lines of assembly, and students get to see a working multitasking system without drowning in complexity. They can even modify the scheduler (like implementing a simple priority by altering the ready queue order) as an exercise, which would be much harder in a fully preemptive system.

# 7. IPC & Communication

Inter-Process Communication (IPC): To support interaction between processes in this cooperative environment, PascalOS provides simple and explicit IPC mechanisms, borrowing ideas from OS-9's designs. The goals are safety, determinism, and clarity. We avoid complex implicit mechanisms (like shared global memory or complicated signals) in favor of straightforward message passing and well-controlled shared resources.

Message Passing via Mailboxes: A primary IPC primitive is a message mailbox. A mailbox is essentially a queue (buffer) that one or more tasks can send messages to, and one or more tasks can receive from. In OS-9, some analogous concepts were signals, events, and pipes  $^{34}$ . We'll implement mailboxes as follows: - A mailbox is a kernel-managed object identified by an ID or name. It can be created by a process (e.g. CreateMailbox(maxMessages)). Processes can Send_mailbox, message) and Receive gmailbox, buffer) through system calls. - If a process tries to receive from an empty mailbox, the kernel will put it into waiting state until a message arrives. This is a natural yield point - the scheduler will run other tasks until some sender posts a message. - If a mailbox is full (to avoid unbounded memory, we can have a max queue length), a sender could either block or get an error; we likely choose to block senders as well, to implement backpressure (or we provide both blocking and non-blocking send calls).

Messages themselves can be a fixed-size struct or a pointer to a data module. For simplicity, imagine messages are just small records (like a few integers or a defined Pascal record) - this keeps things deterministic. We also avoid any complicated routing: the mailbox is a direct rendezvous point.

This mechanism is safe because the kernel controls memory access: the messages can be copied from sender to kernel buffer to receiver, ensuring one process can't corrupt another's memory. It's also easier to reason about than shared memory because each transfer is explicit.

Pipes/Streams: Alternatively, we can implement pipes for byte-stream communication. OS-9 had pipe drivers and allowed treating pipes as special devices. We might do something similar: a pipe is like a mailbox of bytes (or a ring buffer). A producer writes bytes into it, a consumer reads bytes out in FIFO order. The semantics are similar: read blocks if empty, write blocks (or fails) if full. This can be built on the same underlying mechanism as mailboxes but oriented to unstructured byte flow (which might be useful for implementing, say, a shell pipeline or a logging channel).

Shared Memory: While message passing is preferred for safety, we do allow shared memory via data modules (as mentioned in memory and modules sections). A data module can be created, given a name,

and another process can link to it (which maps the same physical memory into both processes' address spaces). This is akin to OS-9's ability to create memory modules for data sharing  $^{30}$ . However, we enforce discipline: - Only trusted or cooperating processes should use shared memory, since once shared, the protection is loosened between those processes. - The OS can mark a shared data module as read-only for one side to enforce one-way data flow if needed.

For example, if two tasks need to share a large buffer of readings (say from a sensor), one can create a data module "SensorBuf" and the other can attach to it. Both can then access it directly. This is efficient but requires understanding of potential race conditions, which is a good advanced topic for students. We encourage using message passing for most needs and only use shared memory modules for cases where copying would be too slow or to illustrate how shared memory works.

Device I/O as IPC: In OS-9, I/O operations were done by opening device paths and reading/writing, which under the hood was like sending requests to device drivers. We emulate that idea: - When a process opens a device (say "/Term"), it gets a handle that is essentially a reference to the driver and perhaps a mailbox or buffer associated with that device. - Writing to the device sends data to the driver (maybe via a buffer the driver monitors), and reading from the device might block until data is available (like keyboard input). - This uniform "everything is a stream or message" model simplifies learning: whether inter-process or process-to-device, it's all sending/receiving messages or bytes.

Signals/Events: OS-9 also had software signals and events. We can implement a simple signaling: e.g., a process can send a signal (an asynchronous notification) to another. Because we have cooperative scheduling, we won't interrupt the target process immediately; instead, we set a flag that when the target next enters the kernel (e.g., on yield or system call), the kernel will deliver the signal (possibly by running a small handler or setting a code). This is similar to how OS-9 signals worked – they weren't delivered at the exact time of interrupt like Unix, but at safe points. For simplicity, we might just reuse mailboxes for signals (each process could have a default mailbox for "signals" of certain types).

Determinism in IPC: The system is designed so that IPC operations have deterministic behavior: - No surprise wakeups: a task only wakes when a message is truly there or an event happened it was waiting for. - The order of message delivery is well-defined (FIFO order in mailboxes, for instance). - If multiple tasks are waiting on the same mailbox, we can wake them in priority or FIFO order, but since we have cooperative scheduling without priorities, FIFO is fine - tasks blocked first get served first.

Pedagogical Approach: By using these simple IPC mechanisms, students learn multiple synchronization models: - Blocking receive teaches the idea of waiting and context switching on events. - Producer/consumer problems can be demonstrated with pipes or mailboxes. - Shared memory shows the need for synchronization primitives (we could introduce a simple semaphore or lock for use with shared memory if needed, which could itself be implemented as a tiny counter plus a waiting list).

But importantly, because we're in a cooperative world, even something like a mutex can be implemented in userspace fairly easily (no need for atomic instructions on single-core coop tasks; a simple "if-locked then wait" works because no preemption occurs during the check). This ties into how SuperPascal's language supports parallel processes with channels – in fact, the language itself has channel communication (as per Brinch Hansen's design)  $^{35}$ $^{36}$ . If we leverage SuperPascal's channels, we might map our IPC to those: a channel in SuperPascal could be implemented by a mailbox under the hood. Thus students writing parallel SuperPascal programs on this OS might actually use send and receive from the language, which we

implement in the runtime to call our OS IPC. This is a beautiful unification of concept: they learn about message passing in theory (from the language's perspective) and see it realized in practice (in the OS).

Device Communication Example: Suppose a process wants to read a line from the console. In our OS, the console driver might create a mailbox "ConsoleIn". When the user types characters, an interrupt or polling routine puts characters into that mailbox. The reading process does Receive(ConsoleIn, buf). If no line is available, the process blocks. When the user finally hits Enter (newline), the driver sends a message (the line) to the mailbox. The process wakes up and gets the message. This is deterministic and easy to follow, as opposed to signals or complex TTY line disciplines in Unix. We sacrifice some performance (due to copying the data maybe twice) for simplicity, but with such small scale that's fine.

In summary, IPC in PascalOS favors explicit synchronization. Nothing happens behind your back - processes must take action to communicate or synchronize. This explicitness ensures that a learner can always answer "how do these two tasks talk or coordinate?" by pointing at a specific OS object or call. And because we are not preemptive, you won't have weird half-updated shared variables; either you use a message (safe by design) or if you share memory, you manage it explicitly (which we can demonstrate with simple critical sections or by the inherent safety of SuperPascal's disjoint variable rule for parallel processes 37).

# 8. Device Driver Model

Modular Drivers: Devices in PascalOS are handled by a modular driver model reminiscent of OS-9's separated drivers and descriptors. Each hardware device (timer, serial port, video, etc.) has an associated device driver module - which is code (ideally in SuperPascal with minimal assembly for direct hardware access) - and a device descriptor which contains configuration data (I/O addresses, buffer sizes, etc.) for that specific instance. This separation is pedagogical: it shows the difference between generic driver code and specific device settings.

- A Device Driver Module is a piece of code (marked with type "Drivr" in the module header) that implements a standard interface. In OS-9, a driver had a table of function offsets for init, read, write, getstat, setstat, etc. 28 38 . We will follow a similar approach. For example, a driver module might have procedures Init(devDesc), Read(request), Write(request), etc. The driver is typically reentrant (no global static data, or declared as system state if needed) so it can serve multiple devices or callers simultaneously (under our cooperative assumptions, it won't be interrupted mid-operation, but it could be invoked by different processes serially).  
- A Device Descriptor is a data module (structure) that contains the specifics for one device. For instance, for a serial port, the descriptor might include the base memory address of the UART registers, the interrupt number (if any) or polling interval, the baud rate, and a link to which driver to use. In OS-9, descriptors were even separate module types (type "Devic")  $^{39}$ . For us, we might not need to expose them as full modules, but we will at least define them in a table the kernel loads at boot (perhaps compiled in or in a config file).

Driver Loading & Binding: At boot time, after the kernel is up, it will load all necessary driver modules (either from ROM or disk) and device descriptors. For example, a descriptor for "/Console" will be loaded which references the TTY driver module. The kernel then calls each driver's init routine with each descriptor that uses it. The driver can then perform any hardware initialization (set baud rate registers, etc.) and allocate any required buffers (some drivers use internal buffers for input/output).

Because drivers are modules, they can be dynamically loaded and unloaded. In a teaching scenario, one could load a new driver at runtime (say a new file system driver, or an experimental driver a student wrote) without rebooting the OS. This dynamic capability, inherited from OS-9, shows how an OS can be extensible.

Character vs Block Devices: We categorize devices roughly: - Character devices: those that deal with streams of characters or bytes (serial port, keyboard, console, printers). These typically implement Read/Write operations that handle variable-length data, possibly line-buffering for terminals. - Block devices: those that read/write blocks of data randomly (disk storage like SD card interface). They might implement operations like ReadBlock(blockNumber) and caching strategies. A block driver can serve a filesystem.

Our driver API will reflect these differences but also try to unify where possible. Possibly we provide a generic DeviceIO(dev, operation, params) system call and drivers interpret the operation code (like OS-9's I$Read, I$Write, etc.). However, in high-level Pascal, we might instead expose specific procedures or methods to call.

Console / Serial I/O Example: The console (the main text output and input) might be handled by a console driver built on top of a lower-level serial or video driver: - If our educational computer uses a serial port for console, the serial driver deals with hardware registers. It generates an interrupt (or is polled) when a key is pressed or when the transmit buffer is empty, etc. The serial driver might fill an input buffer and signal a waiting process (like the shell) via a mailbox (as described in IPC). - The console driver could add processing like interpreting special keys, implementing backspace, simple line editing. Or we might keep console simple and let the shell handle it. - Serial driver code: likely mostly assembly to handle bit-level hardware, but wrapped in a Pascal interface for the OS. For instance, an assembly ISR reads a byte from UART into a ring buffer, then a Pascal routine is called to enqueue a message to the waiting process.

Isolation from Kernel Core: Drivers run in system state, but we try to keep them separate from the core kernel logic. This means a bug in a driver ideally shouldn't corrupt unrelated kernel structures. We achieve this by two means: 1. Memory isolation: If possible, run the driver code in the same fixed kernel 8KB window but restricting what it touches. In practice, since we lack hardware enforcement of privileges, we rely on drivers being written in SuperPascal with discipline (no wild pointer writes), and code review since this is an educational OS and drivers are open for students to inspect. 2. Module interface: Drivers interact with the rest of OS through well-defined calls (they may call some kernel utility functions like to allocate memory, or they receive requests via the system call interface). We avoid entangling driver logic with scheduler or memory manager logic. For example, the file system might call a disk driver's function to read a block; the driver will perform it and return, but it doesn't meddle with process scheduling except to maybe block the calling process until I/O completes. We don't allow drivers to spawn arbitrary processes or do weird stuff outside their domain.

Driver as a Process? In some simple OS designs, drivers are run as separate processes (especially in microkernels). We could adopt a simplified version: treat each driver as a special process that waits for I/O requests (sent via a message queue). For instance, a disk driver could be an infinite loop waiting on a "DiskRequest" mailbox; when a file system process sends a request (read sector N), the driver process handles it (performs the actual hardware I/O, possibly by polling or waiting on an interrupt event), then replies. This would fit nicely with our cooperative model and emphasize separation. It does mean context switching into the driver process, but since everything is coop, that's fine. This approach might be slightly advanced to implement initially, so perhaps we keep drivers as subroutines in kernel space at first and later show how to convert one into a process (which could be an exercise or advanced topic).

For now, assume drivers are primarily invoked via system calls but can block the caller and later wake it up when done (essentially doing asynchronous work via interrupts).

Example - SD Card Driver: The system includes, say, an SD card via an SPI interface on a Raspberry Pi Pico acting as a south bridge. The SD card driver could be structured as: - A driver module that knows how to send SPI commands for read/write. - It exposes operations like ReadSector(n, buffer) and WriteSector(n, buffer). - The filesystem code calls these operations. If using polling, it might busy wait for completion (with yields inside the wait loops to let others run). If using interrupts (maybe the RP2040 can signal completion), the driver would put the calling process to sleep and an interrupt handler will wake it when data is ready. - All the low-level details (timing, protocol) are encapsulated in this module, which can be studied or replaced independently.

Educational Merit: This driver model shows students how modularization extends to hardware interfacing. They can see: - How a new device is added to the system without altering the kernel (just by adding a module and a descriptor). - How hardware specifics are abstracted behind a software interface. - How resource access works (e.g., two processes writing to the same device go through one driver that serializes the requests). - The difference between blocking I/O and non-blocking (e.g., a driver could offer both, illustrating those concepts). - Writing a simple driver in Pascal (e.g., a pseudo-driver that generates synthetic data, or an LED-blinking driver) as a lab exercise.

Overall, the device driver model of PascalOS is modular, dynamic, and isolated in spirit. It owes a lot to OS-9's proven design where even drivers were just modules in the module list 40 . By reusing that concept, we ensure that a high-schooler can follow how a character typed on keyboard ends up in a user program: through a chain of modules (keyboard hardware -> driver -> OS message -> application). Each link in that chain is explicit and available for inspection.

# 9. Filesystem

Simple, Deterministic Filesystem: PascalOS includes a filesystem, but we intentionally keep it simple and limited. The goal is to provide persistent storage for programs and data in a way that's easy to understand and has predictable behavior. We avoid the complexity of advanced features (no huge directory trees with complicated permissions or journaling). The emphasis is on demonstrating the basics: organizing data into files, directories, and ensuring data can be saved and loaded.

Storage Medium: The educational computer uses a CompactFlash or SD card for storage (with a Raspberry Pi RP2040-based "south bridge" handling low-level I/O). We treat this as a block device (like a disk) accessible via the block driver. The storage might be preformatted with a simple filesystem or one the OS creates at first boot.

Filesystem Structure: We can implement a minimalistic filesystem, possibly inspired by old designs: - A FAT-like filesystem is an option (FAT16 or FAT32) because it's well-documented and simple. But FAT has some complexity (boot sector, FAT tables) that might not be necessary. - Alternatively, an OS-9 File System was used historically, which had an indexed sector scheme (with an allocation bitmap and list of sectors per file). OS-9's filesystem was hierarchical and fairly advanced for its time. - Given educational needs, we might define our own super-simple FS: - A fixed-size root directory (array of entries) that holds file names and their start block and length. - Each file occupies contiguous blocks on the disk (contiguous allocation).

This simplifies things greatly (just like a tape or very simple disk OS). It does mean fragmentation can become an issue if files are deleted and vary in size, but we could mandate, for learning's sake, that students manage files or we include a compaction tool. - Or we use a linked allocation (each block has a pointer to next). This is like FAT but we could implement it in a straightforward way, keeping a table in RAM.

We'll assume a modest storage size (maybe the card is 32MB or 64MB for plenty of space relative to RAM). With contiguous allocation, the directory might have an entry: filename, start_block, length_in_blocks. To find a file, scan directory for name, then read those blocks. To create a file, find free space (we keep a simple free-block bitmap), allocate a contiguous run if possible, otherwise possibly refuse if fragmentation (again, we could implement a more complex scheme if needed).

Boot vs Runtime Filesystems: We might differentiate between a boot ROM FS (for initial modules) and the main disk FS: - The OS kernel and fundamental modules could reside in ROM (for a completely diskless boot if needed). But since we have a loader in ROM that loads the kernel from disk, likely the disk (SD) itself has all needed files. - The boot filesystem might just be the same as the runtime FS, just that the bootloader knows how to find the "Kernel" module file. - Alternatively, the monitor in ROM might contain a tiny FS driver that understands a specific format or a fixed location to load the kernel. - For simplicity, assume the SD card has a known file (e.g.  $\boxed{\mathrm{KERNEL . MOD}}$ ) at a fixed location or in a small FAT partition that the ROM can find, then the full FS is mounted by the OS.

File Types: We consider a few file types: - Executable modules: files that contain OS-9 modules (with headers). These can be loaded into memory and executed. The OS might directly load modules from the filesystem as needed (this ties file I/O to the module loader). - Text/data files: for user documents or source code, etc. Basic open-read-write-close operations will be supported. These operations go through the filesystem manager, which uses the block driver underneath. - Possibly Directory files: if we support subdirectories. Initially, we might restrict to a flat filesystem (all files in one directory) for simplicity. That's easier for beginners to grasp (like the old DOS 2.0 before directories, or a CP/M disk). If desired, we can extend to directories later, which teaches tree structures.

Deterministic Operation: We ensure that file operations are not overly unpredictable: - No background write-back caching (we can do immediate writes to keep it simple, or have a very clear commit step). - File read/write either completes fully or returns an error, no partial asynchronous behavior (except that the calling process may block while the driver fetches the data). - The filesystem code itself can be mostly in SuperPascal, stepping through directory entries and block lists. This code will be straightforward and visible to students, unlike opaque code in modern OS.

Limited Complexity: We won't implement features like file permissions (maybe a rudimentary read/write flag), user ownership, or access control beyond what's needed. In a single-user educational context, that's fine. The focus is on how bits on disk translate to structured data.

Integration with Module System: A nice synergy is that programs are files (modules) on disk, which the OS can load. For instance, when a user at the shell types a command, the OS will: 1. Look for a module with that name in the module directory (memory). 2. If not found, attempt to load a file of that name from disk. 3. The file is an OS-9 module file, which the OS reads (using the filesystem layer), verifies, then creates a process from it.

Thus, the filesystem doesn't need to know about modules specifically; it just provides the bytes. But conceptually, students see a coherent picture: files hold modules, and modules implement the programs and even parts of OS.

Raspberry Pi Pico (RP2040) South Bridge: Because we assume a Raspberry Pi microcontroller is aiding with I/O (like handling SD card protocol, possibly as a sort of intelligent controller), the complexity of, say, SD card SPI timing can be offloaded. Perhaps the RP2040 presents a simple interface (like memory-mapped registers or a high-level command interface) to read/write sectors. This is not unlike having a disk controller that the OS interacts with at a high level (e.g., send sector number and read command, then wait for a ready flag). For the OS's perspective and the student's perspective, this means: - They don't need to implement the full SD card spec in the OS; they can focus on sending commands to that controller and getting data. - The drivers then include a "block device driver" that speaks to the RP2040. Possibly via a memory-mapped FIFO or via a serial link. This could be as simple as writing the sector number to an address, triggering a read, and then reading 512 bytes from a buffer the Pico fills.

We might document that as part of the device driver implementation. It's a bit hardware-specific, but again, isolating it in a driver means the core OS (like the filesystem code) doesn't change if the hardware changes.

Why Limited Complexity: We explicitly limit the filesystem's features to keep it digestible: - No large-scale optimization (no caching beyond maybe one sector). - No concurrency issues (with cooperative tasks, we can have a simple lock in the filesystem code that only one process accesses the disk at a time, avoiding the need for complex synchronization in the FS). - A single, simple allocation structure (like a bitmap for free blocks) that can be drawn and understood.

If a student looks at an inode structure from Linux, they might be overwhelmed; but if they see "directory entry with name and start block" and " bitmap of free blocks", they can directly correlate it to what they learned in class about filesystems.

Educational Progression: In early phases, we might not even implement the filesystem fully – the OS could load a couple of programs from fixed flash addresses. As we progress (Phase 3 or 4 in Section 12), we add the filesystem, and students learn about it then, when they have enough context to appreciate persistent storage. By the final phase, they can write and run their own programs that create and save files (maybe a simple text editor or data logger), completing the picture of an OS that can store state.

# 10. Fault Handling & Debugging

MMU Faults via NMI/Abort: The 65C816, as mentioned, has a special Abort input and vector for memory faults. In our design, the CPLD MMU is wired to assert this line whenever a memory access is invalid - e.g., a process tries to access a page that is not in its map or writes to a write-protected page. This generates a non-maskable interrupt (NMI) to the CPU (or specifically triggers the Abort exception vector). The kernel has an assembly-level Abort handler that immediately transfers control to a fault handling routine in the kernel (in SuperPascal, if possible, after saving state).

Handling Memory Violations: When a fault occurs, the OS must determine the cause and respond without crashing the whole system. We implement a simple strategy: - Identify the process that was running (likely a global variable `currentProcess` tells us). - Determine the offending address and type of fault. The MMU

might provide some info (if the CPLD latches the page number or reason). If not, the OS can inspect the instruction or simply know it was an invalid address. - Print or log a fault message: e.g., "Process 3 accessed invalid memory at 0xB200, terminated." This would typically go to the console for educational effect (the student sees that their program did something wrong). - Terminate the process gracefully (as per Section 3: free resources, remove from scheduler). Possibly, if this is a development scenario, return to the shell or monitor.

The OS might also produce a mini dump for learning: for instance, output the process's register state at time of crash, or the instruction opcode that faulted. This gives students insight into what went wrong (similar to a simple kernel panic but only for that process).

Surviving Crashes: Because of memory protection, a wild pointer in one program won't overwrite OS or other processes - it triggers a fault. Thus the OS itself remains stable. The cooperative nature means we don't have to worry about a fault happening exactly in the middle of updating a critical kernel structure (since that wouldn't be running if user code is active - unless the fault occurs during a system call, in which case it's likely a kernel bug rather than user error). If a kernel bug occurs (like a null pointer in the OS code), that is more severe. We can still use similar mechanisms: we might use the 6502/65816 BRK instruction or a dedicated "trap" for internal sanity checks. For example, if the kernel detects an inconsistent state, it could call a routine that prints "Kernel assertion failed, halting". In an educational OS, it's acceptable to halt on kernel errors - but we try to catch them with design.

Faults Beyond MMU: Other exceptions: - Illegal instructions or CPU exceptions: The 65C816 has a COP (co-processor) instruction that can be used as a software interrupt. If a process executes a truly undefined opcode or something, in emulation mode it might just treat as NOP or in native maybe it has WDM (reserved). Those likely won't occur unless error in program binary. If so, we treat it similar to a fault and kill the process. - Division by zero or overflow: The CPU sets flags but doesn't trap on those. We could manually check if needed, but probably not - we leave such logic errors to be handled by program logic or runtime library (if any). - Interrupt handling faults: If an interrupt occurs and finds nothing to do (like spurious) we just return. If a device fault (like missing device) occurs, the driver should catch it and probably also terminate or signal error to process.

Debugging Support: Since this is an educational system, we incorporate features to aid debugging: - ROM Monitor: The initial monitor can be re-invoked if needed. For instance, if no processes are running, the OS could drop into a monitor mode where the user can inspect memory or registers. Perhaps pressing a special key in the console triggers a break into the monitor (simulating a breakpoint). - Software Breakpoints: We can implement a simple breakpoint mechanism. If the user (or a student's program) wants to break into the monitor, they could execute the WDM (reserved instruction) or COP instruction which we define to trap to the monitor. This way, while testing, you can insert such instructions in code to inspect state. The OS's COP handler would save state and print out, or transfer control to the ROM monitor. - Step-by-step Execution: Because of deterministic scheduling, one can single-step through one process without others interfering (if we freeze scheduling in the monitor). The monitor could allow step or continue functionality for the currently active process. - Tracing: We might include an optional tracing feature: e.g., compile the OS or user program with a flag that prints each system call or significant event to the console. This can be used to illustrate the sequence of events. For example, trace output might show: "Task1: F$Fork executed, new Process4 created", "Process4: Mapping module X", "Process4: Exception fault at ...". - Assertion Checks: In the kernel code (Pascal), we use assertions generously. If a data structure is found in

an unexpected state, an assertion can trigger a breakpoint or at least a console error. This helps catch errors early rather than causing weird behavior later.

Containment of Device Faults: If a driver misbehaves (say the disk read fails or times out), how do we handle it? We can propagate an error to the process trying to use it (like return an I/O error code and possibly terminate the process if it cannot handle it). The OS should not hang indefinitely. For example, implement a time-out in the driver: if no response in X milliseconds, abort the request and signal error. A waiting process would then wake with an error code. This prevents a dead driver from hanging all of OS (though if it hung with interrupts off, that's bad - we avoid disabling interrupts for long or at all in cooperative design).

Resilience: Even though cooperative multitasking doesn't protect against a stuck process, we can mitigate: - A watchdog timer (maybe a hardware timer in the RP2040) could reset the system if interrupts are not serviced (implying the OS hung). Or we could have a non-maskable periodic tick that at least updates a global counter and if that counter doesn't change, an external circuit resets. This is more for a real hardware scenario; in class, if you hang the OS, resetting the board manually might be fine.

However, often just hitting the reset button or power-cycling is the fallback. This is acceptable in a learning scenario, though we try to make software robust enough that only infinite loops cause that.

User Program Debugging: For user programs, we can provide a simple debugger that uses the OS's services. Perhaps a "debug monitor" program can be loaded which uses system calls to read/write another process's memory (if allowed) or to set breakpoints (maybe by writing a break instruction into the target's code). Given the scope, a full debugger is probably beyond what we want to implement, but we can allow the ROM monitor to inspect any memory, including a user process's memory, since all physical memory is accessible if the MMU is turned off or via a kernel service. So a student can at least examine the values of variables in their program if they know where to look (which could be aided by symbol information if we had that, but likely not).

Teaching Debugging: We explicitly teach how faults are an opportunity to learn: - When a program crashes with a memory fault, students learn about segmentation faults the easy way (with a controlled message rather than a cryptic crash). - The OS encourages adding checks - e.g., array bounds could be checked in software (SuperPascal might already enforce some, since Pascal often does range checking). - We demonstrate how an OS isolates errors, such that one buggy program doesn't take down others - reinforcing the value of memory protection and process isolation.

In short, robust fault handling ensures PascalOS is a forgiving playground. Crashes are contained and reported clearly, and the system provides the necessary hooks (monitor, traces, assertions) to debug issues rather than leaving the user blind. This fosters an environment where learners aren't afraid to experiment at the OS level because mistakes are caught and explained, not resulting in mysterious hangs (most of the time, anyway!).

# 11. SuperPascal Language Integration

Language-Driven Design: PascalOS is fundamentally shaped by the capabilities and constraints of the SuperPascal language. Using SuperPascal (a safe, structured concurrent language) to implement the

OS enforces certain design decisions that enhance safety and clarity. We treat the language not just as an implementation tool but as part of the trusted computing base: the language's rules help us avoid needing hardware-enforced protection in some areas, because the compiler and runtime catch issues.

Memory Safety & Pointer Restrictions: SuperPascal is a secure subset of Pascal – notably, it omits unsafe features like unrestricted pointers, goto statements, and variant records that could break type safety. There are no raw pointer arithmetic or casting to speak of (it doesn't allow arbitrary address poking). This means a lot of the memory safety that other OSes rely on hardware for is partly achieved by language safety: - A kernel programmer in SuperPascal cannot accidentally write to an arbitrary memory address; they would work with high-level constructs (arrays, records) that the compiler bounds-checks. For instance, if we have an array of 8 MMU entries, accessing entry 9 will be caught by the runtime or compile-time range check rather than corrupting memory. - The absence of general pointers means we don't do pointer math. If absolutely needed (like to interface with a memory-mapped device at a specific address), we provide a controlled mechanism (perhaps a special library or a Pascal function that safely wraps an address access). For example, an inline assembly or a special type for memory-mapped registers might be allowed in small doses, but not something students will misuse accidentally.

Region-Based Allocation: SuperPascal encourages a structured approach to memory allocation. While not explicitly a "region-based memory management" language in implementation, we design the OS such that allocations are done in coarse regions: - Each process's memory (stack, data, etc.) is allocated as a block when the process is created and freed when the process terminates. This is essentially region allocation per process lifetime. - Temporary allocations inside the kernel can often be avoided or use static buffers, given the OS's limited scope. If needed, we could implement a simple region or pool for kernel allocations that gets reset on certain events. - Because modules declare their memory requirements in headers, the OS can allocate exactly one chunk for that module's data and one for its stack. There isn't rampant malloc/free churn as in typical programs. - If we implement dynamic memory allocation for user processes (like a simple new in Pascal), it will likely use a very simple heap mechanism within that process's region, or we encourage use of fixed-size buffers and structures to reduce fragmentation.

This "region" idea is pedagogically useful: it matches well with how Pascal programs usually work (stack for local variables, static/global for others, maybe one heap for dynamic but often not heavily used in systems programming).

Language Rules vs Hardware Enforcement: Because we can trust SuperPascal code to a higher degree, we can sometimes relax reliance on hardware. For example: - No need for hardware execution protection: In a typical OS, you'd worry about user code jumping into the middle of kernel code. In PascalOS, user programs will themselves be written in SuperPascal (or a similarly safe language). They won't easily have the capability to craft an arbitrary jump into kernel space – especially if we don't give them an assembler. The system call interface will be through well-defined Pascal procedures, not numeric trap codes that user can try to exploit. In effect, the language runtime acts as a gatekeeper. This is similar in spirit to systems like Java operating systems or Singularity (a research OS in C#) where language safety replaces some of the hardware memory protection. - Parallel process safety: SuperPascal's concurrency model requires that parallel processes do not interfere with each other's variables unless explicitly allowed. The compiler checks that parallel processes are disjoint in memory usage (no data races)  $^{37}$ $^{41}$ . This is an amazing feature: it means if we structure our OS and user programs as parallel sections, the language guarantees no unintended race conditions. For instance, if two threads (lightweight processes in the same program) are started, the compiler forces them to either use separate variables or coordinate via channels.

This deterministic parallelism aligns with our OS philosophy of avoiding unpredictable interactions. - Because of that, even if we had threads within one process sharing memory, the language ensures they won't step on each other unless we explicitly allow it. That relieves the OS from policing some of these conditions at runtime.

SuperPascal's Parallel Constructs and OS Tasks: SuperPascal provides high-level parallel constructs (like parallel ... end blocks and for all loops) and communication channels for processes 42 43. We can leverage these for implementing OS-level concurrency: - The OS's own background tasks (like a idle task, or a periodic task) could be written as parallel blocks inside the kernel main. For example:

```txt
parallel
TaskScheduler(); (* one parallel process running the scheduler loop *)  
DevicePoller(); (* another that polls devices if needed *)  
end
```

The compiler and language will ensure these two have disjoint state (unless using shared memory safely). - However, the actual OS context switching is outside of the language's built-in concurrency (since it's cooperative multitasking at system level). But nothing stops us from using the channel concept of SuperPascal to implement our IPC: indeed, the send() and receive() operations from SuperPascal can be tied to our mailbox system 36. So a user program can use channels and behind the scenes, the runtime calls OS traps to send/receive from mailboxes. This allows user-level concurrent Pascal programs to run on our OS nicely, teaching event-driven or message-passing concurrency from both language and OS perspectives.

Pedagogical Power: Using SuperPascal shapes the educational experience: - Students see a uniform language from top (application) to bottom (kernel). There is no abrupt switch to another language for kernel (like C for kernel and Python for apps in some OS courses). This uniformity demystifies kernel development - it's just another program following the same rules they know, only with more privileges. - It demonstrates that high-level languages can be used for systems programming. Historically, OS-9 itself was written in assembly and C. Here we show Pascal (a structured, safe language) can achieve similar goals, echoing works like Niklaus Wirth's Oberon OS which was written in Modula-2 or Oberon. It reinforces good practices: strong typing, clear structure, which are beneficial even in low-level code. - No hidden memory bugs: Many OS bugs in C come from memory mismanagement. SuperPascal avoids those by design, so students spend more time learning OS concepts and less time debugging pointer errors. For example, a buffer overflow in C could corrupt adjacent kernel data and lead to a wild goose chase; in Pascal, an array index error would be caught or at least confined. - It teaches the concept of a runtime system: because to run Pascal programs (especially with concurrency), there is a small runtime needed. In our OS, the "runtime" of SuperPascal is essentially integrated with the OS. For instance, channel operations, parallel process launching in a single program, etc., might rely on OS services. Students can learn how a language runtime and OS interact. - The restrictions of the language (no pointer arithmetic, no arbitrary casting) might initially feel limiting, but they encourage better structure. Students will design data structures using arrays and records with fixed sizes, or linked structures via indices instead of raw pointers (which can be safer as the index can be validated).

Performance Considerations: One might ask, can a Pascal-based OS be efficient enough on a 16-bit CPU? The answer lies in the fact that our goals are educational clarity and determinism, not raw speed. The

65C816 at a decent clock and with 16MB RAM is sufficient to run this OS because: - The system is not doing heavy multitasking or background daemons like a modern OS - only the tasks the student runs. - The code, being high-level, might be slightly slower than hand-tuned assembly, but the difference is manageable given the simpler workloads (text, basic graphics, sensors, etc.). - If needed, we can always drop into assembly for hotspots. But we suspect minimal need for that if code is well-structured.

Example of Language Benefit: Suppose we want to implement a bounded buffer for producer-consumer. In C, we'd allocate a buffer, use two indices, and worry about locking. In SuperPascal, we can literally use a channel of a certain type and the language ensures sends block when the buffer is full (if using channel semantics similar to CSP). If our runtime uses mailboxes to implement channels, we get this high-level behavior almost for free. The code in the OS to implement channel send/receive can even leverage the knowledge that the compiler ensures only matching send/receives happen (no type mismatches or wrong threads), simplifying the needed error checking.

Memory Management by Language: Also, because Pascal does not implicitly garbage collect (and we've avoided complex dynamic allocation), we don't have an unpredictable GC pause or such. Memory is either static or manually managed. That said, in our OS we might avoid using Pascal new and dispose for kernel structures entirely – prefer static allocation or pool, to keep control.

In conclusion, SuperPascal is not just the implementation language but a guiding framework. It forces the OS to be designed in a modular, safe way: - The code reads almost like pseudocode in textbooks (because that was a goal of SuperPascal 44). - We can present the OS source to students almost as-is and it will be understandable, closer to an algorithm description than to raw machine-oriented code.

This approach empowers learners: they could modify the OS in Pascal (like change the scheduling algorithm or tweak the memory allocation) without needing to master assembly or worry about crashing everything with a stray pointer. It's a very high-level approach to low-level programming, marrying the benefits of both.

# 12. Educational Progression

PascalOS is explicitly designed to be built, understood, and extended in incremental phases, aligning with a student's progression from beginner to advanced over years (ages 13-18 and beyond). Each phase of the OS introduces new concepts and complexity, matching the curriculum's pacing:

# Phase 1: Minimal Single-Task Monitor (No MMU, No Multitasking)

Focus: Basic computer architecture and machine-level programming.

In this initial phase, the system runs essentially as a simple monitor program (like a very basic OS). There is no memory mapping and no multitasking. The hardware is used in its simplest mode (65C816 in linear 64KB mode, possibly emulation mode throughout). This phase corresponds to early high-school level or hobbyist beginning: - Students learn how the CPU boots, how the reset vector works, and they get comfortable with assembly by examining or writing the boot ROM code that prints "Hello" or reads from keyboard. - SuperPascal programs can run, but one at a time, and likely without protection. For example, a student might write a Pascal program to blink an LED or echo serial input, and the monitor loads and runs it. - The OS at this point is more of a runtime library: it provides basic I/O routines and maybe a simple file loader from flash/ROM. - Educational outcome: understanding of the reset process, assembly bootstrap, and calling

high-level code. They also appreciate the limitations of a single-task system (you have to reset or manually stop one program to run another).

# Phase 2: Introduction of Cooperative Multitasking

Focus: Core operating system concepts like processes and scheduling.

Now we enhance the OS to support multiple tasks via cooperative scheduling, but still likely without the MMU initially (or MMU in a trivial identity-map mode). This could be introduced in late high school or early university intro to OS: - The OS now has a simple scheduler and can run, say, two or three tasks concurrently. For example, one task could be a blinking LED, another reading a sensor and printing values. Students see both apparently happening "at once". - Implementing this involves teaching about context switching. At this stage, to keep things simple, we might still not enable full memory protection—every task can see the same memory (or we only separate stack spaces by careful allocation but not enforce in hardware). Essentially, it's like threads in a single address space. - The concept of system calls is introduced: e.g., each task calls Yield() or uses OS-provided I/O which internally yields when waiting. -

Educational outcome: students learn about the structure of a process (stack, registers), how the OS switches tasks, and why cooperative multitasking needs well-behaved tasks. They can experiment: what happens if a task never yields? They directly witness starvation and can fix it by adding a yield—an “aha” moment about scheduling.

# Phase 3: Memory Management and Isolation (Enable MMU)

Focus: Virtual memory, memory protection, and safety.

In this phase, typically at the university OS course level, we switch on the MMU and give each process its own address space. This is a significant step: - The OS must now manage page tables, allocate physical memory, and handle faults. Students learn how logical addresses map to physical frames. - Likely, one begins with identity mapping for all processes (just to get it working), then gradually move to isolated maps. For example, first give each process distinct memory but still identity mapping for kernel; later, enforce that one process can't see another's memory at all. - They will observe that a bug in one process (like writing out of bounds) no longer corrupts others—leading to a discussion on why memory protection matters. - They also learn about the overhead: now pointers are different per process, and the OS must do more work on context switch (changing MMU context). - Perhaps an assignment here would be to implement the page frame allocator or the fork/spawn mechanism with memory mapping. - Educational outcome: clear understanding of how an MMU works by directly manipulating it. They could be tasked to draw diagrams of their process memory layout, etc. The concept of a "segmentation fault" or access violation becomes concrete when they intentionally trigger one and see the OS catch it.

# Phase 4: Modules, Drivers, and File System

Focus: System modularity, extensibility, device I/O, and storage.

At this stage, roughly matching an advanced high school project or mid-university course, the OS is extended with dynamic modules, a filesystem, and device drivers: - Students now load modules from disk rather than having everything in one binary. For instance, they update the OS to support loading an application module when the user requests it. They see how the module directory works and implement part of the module loader (like checking the CRC or relocating code). - Device drivers: perhaps they write a simple driver for a new device (e.g., a digital thermometer attached via I/O). They learn the standard driver interface and how to handle hardware registers or interrupts in a safe environment. Possibly they do this in Pascal if plausible, or minimal assembly with Pascal glue. - The file system: they implement file creation, reading, writing. Maybe a lab assignment is to implement a simple directory listing function or to increase the FS's capabilities (like add subdirectories or improve allocation). - By now, the OS can do real things: you

can type commands in a shell, list files, run programs, all in a controlled environment they built. This is incredibly empowering for a student. - Educational outcome: understanding of persistent storage and how OS abstracts devices and files. They also appreciate modular design: if something's wrong in the serial driver, it doesn't crash the whole OS, it can be debugged separately. They see the value of splitting a system into components.

# Phase 5: Full System Maturity - Games and Ecosystem

Focus: Integration, optimization, and application development.

This final phase might be an open-ended project stage (end of high school for exceptional students or a capstone university project). The OS is feature-complete enough to support interesting programs (maybe simple games, complex applications, networking if added via another driver, etc.): - Students can now be users of the OS, writing applications in SuperPascal that use multi-tasking, IPC, and file I/O. For example, writing a simple multiplayer game where processes communicate, or a basic GUI if a display is present, or controlling a robot. - They also learn about performance: maybe they notice the cooperative scheduler can lag if one task is slow, so they explore optimizations or even consider adding (optional) preemption or priorities as an advanced topic. Or they might improve the filesystem's performance or the memory allocator (like implement a better heap algorithm as a challenge). - At this stage, the system's soul (OS-9's influence) and modern clarity come together: they have essentially a mini OS-9 they fully understand. A motivated student could now compare it to how more complex OSes (like Linux or even a modern embeddedRTOS) work, seeing the similarities and differences. - There might be an opportunity to introduce more advanced topics like networking (a simple TCP/IP stack as a module) or graphics (if hardware supports a frame buffer, writing a module to manage video output). - Educational outcome: by the end, a student has basically built an OS from scratch in increments. They have touched every aspect: low-level boot, scheduling, memory, drivers, FS, and user programs. This holistic experience is rare at this level and sets them up extremely well for further studies.

# Mapping to High School vs University:

- High School (ages 13-18): Likely not all students will go through all phases in depth. The early phases are suitable for high school curriculum or extracurricular clubs (e.g., building the hardware, then Phase 1 and 2 to introduce basic OS ideas). Some advanced high schoolers (17-18) could handle simplified Phase 3 (maybe without fully understanding all the MMU details, but enough to use it). - For instance, a high school module could be: "Let's isolate processes so a crashing game doesn't crash your music player." They can implement that with some guidance. - High schoolers can also do a lot with Phase 5 in terms of using the OS to make fun projects, without necessarily modifying the OS. They become power users and app developers on an OS they have the source for. - University (undergraduate OS course): All phases would be covered in rigorous detail. A possible approach is to have a semester-long project where students start with a provided Phase 1 skeleton and progressively add features each week: - Week 1-2: Boot loader and basic monitor (maybe provided). - Week 3-4: Add multitasking (they write context switch code and a simple scheduler). - Week 5-6: Introduce MMU and implement memory isolation. - Week 7-8: Module loader and dynamic linking (perhaps linking with a provided Pascal compiler output). - Week 9-10: File system implementation (with tests for file create, delete, etc.). - Week 11: Writing a device driver (maybe for a toy device in an emulator or real hardware). - Week 12: Final project: build something cool on your OS (or optimize part of it and measure). This would be an intense but immensely educational project, covering a breadth of OS concepts in a contained environment.

Throughout, the deterministic and modular nature of the OS makes it easier to grade and debug student work. Since the system is small, if something goes wrong, the instructor and student can often find the bug

by inspection or simple tests (contrast with debugging a race in a multi-threaded preemptive kernel — much harder).

We also ensure that at each milestone, the system is functional and testable. For example, after Phase 2, you should be able to run two tasks and see output from both. After Phase 3, you test that one task scribbling memory doesn't affect the other. These concrete demos reinforce the concepts (and serve as checks that the student's implementation works).

Never Losing the Soul: At every stage, we remind the learners of the connection to OS-9 philosophy: - Using modules in Phase 4: "This is exactly how OS-9 did it, and why it's powerful." - Using cooperative tasks: "Early microcomputers and some OSes (like early Mac OS) did it this way; notice how simpler it is and what the trade-offs are." - The overall feel of the system is interactive and responsive like a classic microcomputer OS, not an opaque modern OS. This historical context can spark interest in computing history as well.

Finally, by the end of this progression, a student or class will have a fully operational mini OS that they truly understand inside-out. They could even burn it into ROMs, run it on their self-built 65C816 computer, and showcase it. The experience demystifies operating systems and empowers the next generation of system programmers, all while retaining the charm and proven concepts of OS-9, adapted for clarity and safety in the modern educational landscape.

[PDF] Apple IIGS Firmware Reference Manual - Brutal Deluxe

https://www.brutaldeluxe.fr/documentation/cortland/v2_01_ApplleIIGSFirmwareReferenceManual.pdf

2 4 7 WDC 65C816 - Wikipedia

https://en.wikipedia.org/wiki/WDC_65C816

3 GitHub - c0pperdragon/OS816: An experimental single-board computer using the 65C816

https://github.com/c0pperdragon/OS816

5 6 16 25 30 31 32 OS-9 - Wikipedia

https://en.wikipedia.org/wiki/OS-9

8 9 13 17 18 19 34 Architecture

https://microware.com/index.php/architecture

10 11 33 Cooperative multitasking - Wikipedia

https://en.wikipedia.org/wiki/CooperativeMULTITASKING

12 Cooperative Multitasking system - Stack Overflow

https://stackoverflow.com/questions/14415303/cooperative-multitasking-system

14 20 21 22 23 24 26 27 28 29 38 39 Technical Manual (O-9 V2.4) Table of Contents

https://colorcomputerarchive.com/repo/Documents/Manuals/Operating%20Systems/

OS-9%20v2.4%20Technical%20Reference%20Manual%20(Microware%20Systems%20Corp).pdf

[PDF] Inside OS-9 Level II - Color Computer Archive

https://colorcomputerarchive.com/repo/Documents/Books/Inside%20OS-9%20Level%20II%20(1987)(Kevin%20Darling).pdf

35 36 37 41 42 43 44 SuperPascal - Wikipedia

https://en.wikipedia.org/wiki/SuperPascal
